{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "DQ2nPfbVGiOs"
   },
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import re\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pyarrow\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from typing import Union, Tuple"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Data Integration (extract)\n",
    "## Extracting data from files and combining it into one single data frame"
   ],
   "metadata": {
    "id": "ljBaAC0P0sq9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def extract(file_path: str) -> pd.DataFrame:\n",
    "    # created 3 different lists which contain the data files - 1 for each type of file\n",
    "    csv_files = glob.glob(file_path + '*.csv')\n",
    "    json_files = glob.glob(file_path + '*.json')\n",
    "    parquet_files = glob.glob(file_path + '*.parquet')\n",
    "\n",
    "    # created 3 different empty lists of each file type to store the dataframes\n",
    "    csv_list = []\n",
    "    json_list = []\n",
    "    parquet_list = []\n",
    "\n",
    "    # loop through the list of glob csv files and read/convert each one into a data frame\n",
    "    # and append it to the list that will contain the newly converted csv data frames\n",
    "    for csv in csv_files:\n",
    "      temp_df = pd.read_csv(csv)\n",
    "      csv_list.append(temp_df)\n",
    "\n",
    "    # concatenate the newly converted list of csv data frames into one\n",
    "    csv_df = pd.concat(csv_list, axis=0)\n",
    "    print(f\"CSV shape: {csv_df.shape} \\n\")\n",
    "    csv_df.head()\n",
    "\n",
    "    # loop through the list of glob JSON files and read/convert each one into a data frame\n",
    "    # and append it to the list that will contain the newly converted JSON data frames\n",
    "    for json in json_files:\n",
    "        temp_df = pd.read_json(json, lines=True)\n",
    "        json_list.append(temp_df)\n",
    "\n",
    "    # concatenate the newly converted list of JSON data frames into one\n",
    "    json_df = pd.concat(json_list, axis=0)\n",
    "    print(f\"JSON shape: {json_df.shape} \\n\")\n",
    "    json_df.head()\n",
    "\n",
    "    # loop through the list of glob parquet files and read/convert each one into a data frame\n",
    "    # and append it to the list that will contain the newly converted parquet data frames\n",
    "    for pq in parquet_files:\n",
    "        temp_df = pd.read_parquet(pq)\n",
    "        parquet_list.append(temp_df)\n",
    "\n",
    "    # concatenate the list of parquet data frames into one\n",
    "    parquet_df = pd.concat(parquet_list, axis=0)\n",
    "    print(f\"Parquet shape: {parquet_df.shape} \\n\")\n",
    "    parquet_df.head()\n",
    "\n",
    "    # combine all dataframes into one and return it\n",
    "    combined_df = pd.concat([csv_df, json_df, parquet_df], ignore_index=True)\n",
    "    return combined_df"
   ],
   "metadata": {
    "id": "tXOjj8fWrvUR"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# directory to access for the data files we need is called 'data' and the file path is '/content/data/'\n",
    "# the file path to obtain the data may change obviously, it is dependent upon the machine it is ran and where the data is stored\n",
    "path = './data/'\n",
    "data = extract(path)\n",
    "print(f\"Combined dataframes shape: {data.shape}\")\n",
    "data.head()"
   ],
   "metadata": {
    "id": "gYtJv6x7mP8p"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Data has been extracted, combined into one single data frame; now it is ready for transformation."
   ],
   "metadata": {
    "id": "qWRaSfLwmTWg"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Data Transformation (Transform)"
   ],
   "metadata": {
    "id": "7GErqLZ3E80q"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# check the current data types with data.info() as it won't truncate it unlike data.dtypes()\n",
    "data.info()"
   ],
   "metadata": {
    "id": "fe6XJ4AW1rK2"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# remove the white space from column names\n",
    "data.columns = data.columns.str.strip()"
   ],
   "metadata": {
    "id": "purWUwum1t7s"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# remove 'Heartbleed' attack data\n",
    "data = data[data['Label'] != 'Heartbleed']"
   ],
   "metadata": {
    "id": "FC0Jl8V3EBTH"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# display the number of missing data per column in our 'data' data frame\n",
    "data.isna().sum()"
   ],
   "metadata": {
    "id": "aXetH79n1wGW"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# the following statement is used to determine the total number of missing values\n",
    "print(f'Total number of missing values: {data.isna().sum().sum()}')"
   ],
   "metadata": {
    "id": "SNVRqPRG1ytu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# drop duplicate data values and display the shape to determine if the row (x) value is less than the original value of 61_128\n",
    "data = data.drop_duplicates()\n",
    "data.shape"
   ],
   "metadata": {
    "id": "LdwpaQig11LM"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# print the total number of missing values again after dropping duplicates to determine if there are any\n",
    "# remaining so that they can be handled accordingly\n",
    "print(f'Total number of missing values: {data.isna().sum().sum()}')"
   ],
   "metadata": {
    "id": "iBtjogog14HR"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# handle out-of-range and outlier data: infinite values are replaced with NaNs, which are then filled with column means.\n",
    "\n",
    "# list to contain columns with infinite values\n",
    "cols_with_infinite = []\n",
    "\n",
    "# loop through each column that is a 'number' type (int64, float64) to check for infinite values\n",
    "for column in data.select_dtypes(include=[np.number]).columns:\n",
    "    if data[column].apply(np.isinf).any():\n",
    "        cols_with_infinite.append(column)\n",
    "        count_infinite = data[column].apply(np.isinf).sum()\n",
    "        print(f\"Column '{column}' has {count_infinite} infinite values.\")\n",
    "\n",
    "# display columns with infinite values\n",
    "print(f\"Columns with infinite values: {cols_with_infinite}\")\n",
    "\n",
    "# check for existing NaN values before replacing infinite values - should be 10\n",
    "initial_nans_count = data[cols_with_infinite].isna().sum()\n",
    "print(f\"Initial count of NaN values in 'Flow Bytes/s' and 'Flow Packets/s': \\n{initial_nans_count}\")\n",
    "\n",
    "# replace all infinite values with NaN in the 'Flow Bytes/s' & 'Flow Packets/s' columns\n",
    "data[cols_with_infinite] = data[cols_with_infinite].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# verify that all infinite values in the 'Flow Bytes/s' & 'Flow Packets/s' columns have been replaced with NaN\n",
    "for column in cols_with_infinite:\n",
    "    if data[column].apply(np.isinf).any():\n",
    "        print(f\"Error: Column '{column}' still contains infinite values.\")\n",
    "    else:\n",
    "        print(f\"Success: Column '{column}' no longer contains infinite values.\")\n",
    "\n",
    "# count the number of NaNs in the 'Flow Bytes/s' & 'Flow Packets/s' columns after replacing infinite values\n",
    "nans_count_after_replacement = data[cols_with_infinite].isna().sum()\n",
    "print(f\"Count of NaN values in 'Flow Bytes/s' and 'Flow Packets/s' after replacing infinite values: \\n{nans_count_after_replacement}\")\n",
    "\n",
    "# fill NaNs with the mean of the column in the 'Flow Bytes/s' & 'Flow Packets/s' columns\n",
    "data[cols_with_infinite] = data[cols_with_infinite].fillna(data[cols_with_infinite].mean())\n",
    "\n",
    "# verify that there are no more NaNs in the 'Flow Bytes/s' & 'Flow Packets/s' columns\n",
    "nans_count_after_filling = data[cols_with_infinite].isna().sum()\n",
    "print(f\"Count of NaN values in 'Flow Bytes/s' and 'Flow Packets/s' after filling NaNs: \\n{nans_count_after_filling}\")"
   ],
   "metadata": {
    "id": "QbHPn7wy16lT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# print the total number of missing values again to make sure that it is 0 and that all missing values have been handled\n",
    "print(f'Total number of missing values: {data.isna().sum().sum()}')"
   ],
   "metadata": {
    "id": "uvexbWdW2Axg"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Data has been transformed and is ready for loading to a csv file and database"
   ],
   "metadata": {
    "id": "8hBs9KXE2FQB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Data Storage (Load)"
   ],
   "metadata": {
    "id": "b4LlmnJ5FBWr"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# sqlite database and table names variables created for cleaned data\n",
    "database_name = 'ide_cleaned_db'\n",
    "table_name = 'ntdl_cleaned'"
   ],
   "metadata": {
    "id": "5iNMzwxH2H-E"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# load the data to a csv file\n",
    "def load_to_csv(data_frame: pd.DataFrame, file_name: str) -> None:\n",
    "    data_frame.to_csv(file_name, index=False)"
   ],
   "metadata": {
    "id": "TF0zd0_Bkcwu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# load the data to a sqlite database\n",
    "def load_to_database(data_frame: pd.DataFrame, db_name: str, t_name) -> None:\n",
    "    # add an id column to the data frame for the database as the primary key\n",
    "    if 'id' not in data_frame.columns:\n",
    "        data_frame.reset_index(drop=True, inplace=True)\n",
    "        data_frame.insert(0, 'id', data_frame.index + 1)\n",
    "\n",
    "    # create a connection to sqlite\n",
    "    sqlconnection = sqlite3.connect(db_name)\n",
    "\n",
    "    # load data frame into sqlite specifying table name, SQL connection, if the table exists then replace it, don't index it, and have id be the primary key\n",
    "    data_frame.to_sql(t_name, sqlconnection, if_exists=\"replace\", index=False, dtype={\"id\": \"INTEGER PRIMARY KEY\"})\n",
    "\n",
    "    # close the connection\n",
    "    sqlconnection.close()\n",
    "\n",
    "    # drop the 'id' column as it's only needed when loading to a database\n",
    "    if 'id' in data.columns:\n",
    "        data.drop(columns=['id'], inplace=True)"
   ],
   "metadata": {
    "id": "ihyor1MTkfRw"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# call the 'load_to_csv' and 'load_to_database' functions to perform those actions / tasks\n",
    "load_to_csv(data_frame=data, file_name=\"ide_data_cleaned.csv\")\n",
    "load_to_database(data_frame=data, db_name=database_name, t_name=table_name)"
   ],
   "metadata": {
    "id": "S5NikBnokjBP"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# connect to the database and create a cursor\n",
    "connect = sqlite3.connect(database_name)\n",
    "# database cursor is used to query a database and fetch results\n",
    "cur = connect.cursor()"
   ],
   "metadata": {
    "id": "ORr5jLdmkwKo"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# return values for each row in the ntdl_cleaned table:\n",
    "ntdl_query = f\"PRAGMA table_info({table_name})\"\n",
    "ntdl_result = cur.execute(ntdl_query)\n",
    "ntdl_result.fetchall()"
   ],
   "metadata": {
    "id": "F6G5YSMFk0ya"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# close the connection\n",
    "connect.close()"
   ],
   "metadata": {
    "id": "-kf_Ov8cn6v1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Data has been loaded to a csv file and a SQLite database and is ready for exploratory data analysis"
   ],
   "metadata": {
    "id": "PIuJtkkSl8FS"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# 6. Reading Data",
   "metadata": {
    "id": "UZ9O6BM1Gq6v"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# reading the data (6.1) into a pandas dataframe\n",
    "data = pd.read_csv(\"ide_data_cleaned.csv\")\n",
    "if 'id' in data.columns:\n",
    "    data.drop(columns=['id'], inplace=True)"
   ],
   "metadata": {
    "id": "30XHfsdnNBpf"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 7. Exploratory Data Analysis"
   ],
   "metadata": {
    "id": "AZqZ800WGuIu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Univariate Analysis"
   ],
   "metadata": {
    "id": "30dLeT_5XVzW"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# determine the shape of the data:\n",
    "shape = data.shape\n",
    "print(f\"The dataset contains {shape[0]} rows and {shape[1]} columns.\")"
   ],
   "metadata": {
    "id": "pIiwwYpwQ0LJ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# unify the columns/features names\n",
    "def unify_column_name(name: str) -> str:\n",
    "    name = name.lower().replace(' ', '_')  # replace all spaces with underscores\n",
    "    name = re.sub(r'[^\\w]', '', name)  # remove all non-alphanumeric characters\n",
    "    if name.endswith('ss'):\n",
    "        name = name[:-1] # if the name ends with 'ss', remove the 'ss' and only have it be 's'\n",
    "    return name\n",
    "\n",
    "data.columns = data.columns.map(lambda x: unify_column_name(x))\n",
    "print(f\"Unified column names: \\n{data.columns}\")"
   ],
   "metadata": {
    "id": "6dYUC9GTQyiN"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# identify the unique values in the class label variable\n",
    "unique_labels = data['label'].unique()\n",
    "print(f\"The unique values in the 'label' column are: {unique_labels}\")"
   ],
   "metadata": {
    "id": "np2HrtOjWlKI"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# calculate statistics of data\n",
    "stats = data.describe()\n",
    "print(f\"Statistics of data: \\n{stats}\")"
   ],
   "metadata": {
    "id": "bsj61E8mufJB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# create variable that contains only values that are of type int64 or float64 to calculate statistics of data\n",
    "numeric_data = data.select_dtypes(include=[np.number])"
   ],
   "metadata": {
    "id": "qTXwd-FHVjTD"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# calculate mean of data\n",
    "mean = numeric_data.mean()\n",
    "print(f\"Mean of each column: \\n{mean}\")"
   ],
   "metadata": {
    "id": "_T-VYC4IU1Cr"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# calculate variance of data\n",
    "variance = numeric_data.var()\n",
    "print(f\"Variance of each column: \\n{variance}\")"
   ],
   "metadata": {
    "id": "80dX7PU4ukP8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# calculate standard deviation of data\n",
    "std = numeric_data.std()\n",
    "print(f\"Standard deviation of each column: \\n{std}\")"
   ],
   "metadata": {
    "id": "YpOXE79GunBw"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# identify low variance columns\n",
    "limit = 0.01\n",
    "low_var_columns = variance[variance < limit].index.tolist()\n",
    "print(f\"Columns with low or near zero variance: {low_var_columns}\")"
   ],
   "metadata": {
    "id": "pIGjqrlHuoUg"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# visualizations for specific columns with bar plots, pie charts, and boxplot\n",
    "\n",
    "# bar plot for 'label' column\n",
    "plt.figure(figsize=(10,6))\n",
    "data['label'].value_counts().plot(kind='bar')\n",
    "plt.title('Bar Plot of Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "khWp9XDKuvQ6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# pie chart for 'label' column\n",
    "plt.figure(figsize=(8, 8))\n",
    "data['label'].value_counts().plot(kind='pie', autopct='%1.2f')\n",
    "plt.title('Pie Chart of Label Distribution')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "rugK34TmWqUA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# box plot for 'flow_packets' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=data['flow_packets'])\n",
    "plt.title('Box Plot of Flow Packets')\n",
    "plt.xlabel('Flow Packets')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "gQgft6gtWxV_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# box plot for 'fwd_packet_length_max' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=data['fwd_packet_length_max'])\n",
    "plt.title('Box Plot of Fwd Packet Length Max')\n",
    "plt.xlabel('Fwd Packet Length Max')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "ixe6faI7W3E1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# box plot for 'fwd_packets' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=data['fwd_packets'])\n",
    "plt.title('Box Plot of Fwd Packets')\n",
    "plt.xlabel('Fwd Packets')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "k0N3FzHbW7oT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Bivariate Analysis"
   ],
   "metadata": {
    "id": "HtxXtCLFXCmA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# generating a pair plot for the same columns we performed univariate analysis on\n",
    "columns_for_pair_plot = ['fwd_packet_length_max', 'fwd_packets', 'flow_packets', 'label']\n",
    "sns.pairplot(data[columns_for_pair_plot], hue='label')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "1ssIykO1f6Do"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# computing and generating the correlation matrix\n",
    "correlation_matrix = numeric_data.corr()\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "efcAPcTTuYpY"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Exploratory data analysis has been completed now data is ready for preprocessing."
   ],
   "metadata": {
    "id": "tD5t4-dMiyQi"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 8. Data Preprocessing"
   ],
   "metadata": {
    "id": "O2XhJdJ2i0kV"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# apply lambda function to create binary labels. 0 for benign, 1 for attack\n",
    "data['binary_label'] = data['label'].apply(lambda x: 0 if x.lower() == 'benign' else 1)"
   ],
   "metadata": {
    "id": "T0P0chA7x2NR"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# splitting the dataset into train, test, and validation splits\n",
    "\n",
    "# defines features (X) and target (y)\n",
    "X = data.drop(columns=['label', 'binary_label']) # drop the label & binary_label column from features\n",
    "y = data['binary_label'] # binary labels - the label column is the target\n",
    "\n",
    "# split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# split the training set further into training and validation sets (10% of training data for validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42, stratify=y_train)\n",
    "\n",
    "# print the shapes of the resulting splits to verify\n",
    "print(f\"Training set shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Validation set shape: X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"Testing set shape: X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ],
   "metadata": {
    "id": "F1XmQHfalqeD"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# initialize the LabelEncoder / create an instance of it\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# fit and transform the label column in the training set\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# transform the label column in the validation and testing sets\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# verify the encoding\n",
    "print(f\"Encoded training labels: {y_train_encoded[:25]}\")\n",
    "print(f\"Encoded validation labels: {y_val_encoded[:25]}\")\n",
    "print(f\"Encoded testing labels: {y_test_encoded[:25]}\")\n",
    "\n",
    "# The LabelEncoder will assign:\n",
    "# benign -> 0\n",
    "# DoS -> 1"
   ],
   "metadata": {
    "id": "unZt37bKlsX_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Data has been preprocessed and is ready for feature engineering."
   ],
   "metadata": {
    "id": "EjxwP96_lwpi"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 9. Feature Engineering"
   ],
   "metadata": {
    "id": "eG1Zo6lbl2tI"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# feature scaling\n",
    "\n",
    "# standardizing the data\n",
    "\n",
    "# initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# standardize the data (mean of 0 and a standard deviation of 1)\n",
    "# fit the scaler on the training data and transform it\n",
    "X_train_standardized = scaler.fit_transform(X_train)\n",
    "\n",
    "# transform the validation and testing data using the same scaler\n",
    "X_val_standardized = scaler.transform(X_val)\n",
    "X_test_standardized = scaler.transform(X_test)\n",
    "\n",
    "# convert the standardized data back to a data frame\n",
    "X_train_standardized = pd.DataFrame(X_train_standardized, columns=X_train.columns)\n",
    "X_val_standardized = pd.DataFrame(X_val_standardized, columns=X_val.columns)\n",
    "X_test_standardized = pd.DataFrame(X_test_standardized, columns=X_test.columns)"
   ],
   "metadata": {
    "id": "pROjGxxjl4Sk"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# feature selection\n",
    "\n",
    "# visualize the features' importance\n",
    "\n",
    "# apply SelectKBest with f_classif statistical test\n",
    "k = 'all'\n",
    "selector = SelectKBest(score_func=f_classif, k=k)  # define 'k' for top number of features\n",
    "X_train_kbest = selector.fit_transform(X_train_standardized, y_train_encoded)\n",
    "X_val_kbest = selector.transform(X_val_standardized)\n",
    "X_test_kbest = selector.transform(X_test_standardized)\n",
    "print(f\"Features after SelectKBest: {X_train_kbest.shape[1]}\") # SelectKBest scores and ranks features"
   ],
   "metadata": {
    "id": "pLad7fl7umQ3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get the scores for each feature\n",
    "kbest_scores = selector.scores_\n",
    "\n",
    "# get the selected feature indices\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# get the feature names\n",
    "feature_names = X_train_standardized.columns[selected_indices]\n",
    "\n",
    "# create a DataFrame for better visualization\n",
    "feature_scores_df = pd.DataFrame({'Feature': feature_names, 'Score': kbest_scores[selected_indices]})\n",
    "\n",
    "# sort the DataFrame by scores in descending order for better visualization\n",
    "feature_scores_df = feature_scores_df.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# plot the scores\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.barh(feature_scores_df['Feature'], feature_scores_df['Score'], color='skyblue')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.title(f'Top {k} Feature Importance Scores by SelectKBest')\n",
    "plt.gca().invert_yaxis()  # to display the highest scores on top\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "I9bJgh5GufIp"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# remove constant features\n",
    "constant_features = [col for col in X_train_standardized.columns if X_train_standardized[col].nunique() == 1]\n",
    "\n",
    "X_train_cf = X_train_standardized.drop(columns=constant_features)\n",
    "X_val_cf = X_val_standardized.drop(columns=constant_features)\n",
    "X_test_cf = X_test_standardized.drop(columns=constant_features)\n",
    "print(f\"Features after removing constant features: {X_train_cf.shape[1]}\")"
   ],
   "metadata": {
    "id": "3a8GCzjYmNz0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# remove features with near-zero variance using the previously created list of near-zero variance\n",
    "X_train_vt = X_train_standardized.drop(columns=low_var_columns)\n",
    "X_val_vt = X_val_standardized.drop(columns=low_var_columns)\n",
    "X_test_vt = X_test_standardized.drop(columns=low_var_columns)\n",
    "print(f\"Features after removing near-zero variance: {X_train_vt.shape[1]}\")"
   ],
   "metadata": {
    "id": "UxUDvNPLl9b-"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# perform LASSO feature selection\n",
    "\n",
    "# initialize and fit LassoCV\n",
    "lasso = LassoCV(cv=5, max_iter=20000)\n",
    "lasso.fit(X_train_standardized, y_train_encoded)\n",
    "\n",
    "# select non-zero coefficients\n",
    "lasso_selected_features = np.where(lasso.coef_ != 0)[0]\n",
    "\n",
    "# transform the data to keep only the selected features\n",
    "X_train_lasso = X_train_standardized.iloc[:, lasso_selected_features]\n",
    "X_val_lasso = X_val_standardized.iloc[:, lasso_selected_features]\n",
    "X_test_lasso = X_test_standardized.iloc[:, lasso_selected_features]\n",
    "print(f\"Features after LASSO: {X_train_lasso.shape[1]}\")"
   ],
   "metadata": {
    "id": "QJLggyIomBZQ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# perform tree-based feature importance using random forest\n",
    "\n",
    "# initialize and fit RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_standardized, y_train_encoded)\n",
    "\n",
    "# get feature importances and select top features\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# calculate the threshold using quantiles\n",
    "threshold = np.quantile(importances, 0.75)\n",
    "\n",
    "# select features with importance scores above the threshold\n",
    "top_features = np.where(importances > threshold)[0]\n",
    "\n",
    "# transform the data to keep only the selected features\n",
    "X_train_rf = X_train_standardized.iloc[:, top_features]\n",
    "X_val_rf = X_val_standardized.iloc[:, top_features]\n",
    "X_test_rf = X_test_standardized.iloc[:, top_features]\n",
    "print(f\"Features after Random Forest: {X_train_rf.shape[1]}\")"
   ],
   "metadata": {
    "id": "npvGs1vgmDsZ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# feature extraction\n",
    "\n",
    "# perform PCA for dimensionality reduction\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_standardized)\n",
    "X_val_pca = pca.transform(X_val_standardized)\n",
    "X_test_pca = pca.transform(X_test_standardized)\n",
    "\n",
    "# calculate the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "# plot the cumulative explained variance to determine the number of components\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cumulative_explained_variance, marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# a common practice is to retain enough components to explain a significant portion of the variance in the data\n",
    "# typically aim to keep components that explain around 95% of the variance\n",
    "n_components = np.argmax(cumulative_explained_variance >= 0.95) + 1\n",
    "print(f\"Number of components explaining 95% variance: {n_components}\")\n",
    "\n",
    "# perform PCA with the selected number of components\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_standardized)\n",
    "X_val_pca = pca.transform(X_val_standardized)\n",
    "X_test_pca = pca.transform(X_test_standardized)\n",
    "print(f\"Features after PCA: {X_train_pca.shape[1]}\")\n",
    "\n",
    "# Print the top contributing features for each principal component\n",
    "original_features = X_train_standardized.columns\n",
    "for i in range(n_components):\n",
    "    component = pca.components_[i]\n",
    "    feature_contributions = sorted(zip(original_features, component), key=lambda x: -abs(x[1]))\n",
    "    top_features = feature_contributions[:21]  # get the top 21 features for each component\n",
    "    print(f\"\\nPrincipal Component {i+1}:\")\n",
    "    for feature, weight in top_features:\n",
    "        print(f\"{feature}: {weight}\")"
   ],
   "metadata": {
    "id": "ahkYWlo-mGfU"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Feature engineering has been performed, and the processed data is ready to be loaded to a SQLite database."
   ],
   "metadata": {
    "id": "bPTaeM5DmJPG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 10. Processed Data Loading"
   ],
   "metadata": {
    "id": "NKUbUvIVmNNc"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# sqlite database and table names variables created for processed data\n",
    "database_name = 'ide_cleaned_and_processed_db'\n",
    "\n",
    "X_train_table_name = 'x_train_standardized_data'\n",
    "X_val_table_name = 'x_val_standardized_data'\n",
    "X_test_table_name = 'x_test_standardized_data'"
   ],
   "metadata": {
    "id": "hHTUD_ffmSvp"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# fully processed data loaded into database in separate tables\n",
    "load_to_database(data_frame=X_train_standardized, db_name=database_name, t_name=X_train_table_name)\n",
    "load_to_database(data_frame=X_val_standardized, db_name=database_name, t_name=X_val_table_name)\n",
    "load_to_database(data_frame=X_test_standardized, db_name=database_name, t_name=X_test_table_name)"
   ],
   "metadata": {
    "id": "Vk-Z8Qx_mVOi"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Processed data has been loaded to a SQLite database, now model selection, training, and evaluation will be performed."
   ],
   "metadata": {
    "id": "zB0QshHwmXdQ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 11. Model Selection and Training & 12. Model Evaluation"
   ],
   "metadata": {
    "id": "FxvnVMrAmefQ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# model selection\n",
    "\n",
    "# initialize the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=5000),\n",
    "    \"SVM\": SVC(probability=True, max_iter=5000),\n",
    "    \"k-NN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# function to evaluate model\n",
    "def evaluate_model(m: object, X_: Union[pd.DataFrame, np.ndarray], y_: Union[np.ndarray, pd.Series]) -> Tuple[float, float, float, float, Union[float, str], np.ndarray]:\n",
    "    y_val_pred = m.predict(X_)  # this line makes predictions\n",
    "    y_val_pred_prob = m.predict_proba(X_)[:, 1] if hasattr(model, 'predict_proba') else None  # this line gets probabilities if available\n",
    "\n",
    "    acc = accuracy_score(y_, y_val_pred)\n",
    "    pre = precision_score(y_, y_val_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_, y_val_pred, average='weighted', zero_division=0)\n",
    "    f_1 = f1_score(y_, y_val_pred, average='weighted', zero_division=0)\n",
    "    auc_score = roc_auc_score(y_, y_val_pred_prob) if y_val_pred_prob is not None else 'N/A'\n",
    "\n",
    "    con_matrix = confusion_matrix(y_, y_val_pred)\n",
    "\n",
    "    return acc, pre, rec, f_1, auc_score, con_matrix"
   ],
   "metadata": {
    "id": "B_eAaXaNmhm8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# model training and evaluation\n",
    "\n",
    "# change X_train_, X_val_, X_test_ to equal the other variables that contain different features through feature selection to compare performance:\n",
    "# kbest = SelectKBest features\n",
    "# cf = dropped constant features\n",
    "# vt = dropped low variance threshold features\n",
    "# lasso = lasso selected features\n",
    "# rf = random forest selected features\n",
    "# pca = principal component analysis extracted features\n",
    "X_train_ = pd.DataFrame(X_train_vt)\n",
    "X_val_ = pd.DataFrame(X_val_vt)\n",
    "X_test_ = pd.DataFrame(X_test_vt)\n",
    "\n",
    "# ensure all column names are strings\n",
    "X_train_.columns = X_train_.columns.astype(str)\n",
    "X_val_.columns = X_val_.columns.astype(str)\n",
    "X_test_.columns = X_test_.columns.astype(str)\n",
    "\n",
    "# Dictionary to store model evaluation results for validation and test sets\n",
    "train_val_results = {}\n",
    "test_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_, y_train_encoded) # this line trains the model\n",
    "    \n",
    "    # evaluate on validation set\n",
    "    accuracy, precision, recall, f1, auc, cm = evaluate_model(model, X_val_, y_val_encoded)\n",
    "    train_val_results[model_name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUC\": auc,\n",
    "        \"Confusion Matrix\": cm\n",
    "    }\n",
    "    \n",
    "    # evaluate on the test set\n",
    "    test_accuracy, test_precision, test_recall, test_f1, test_auc, test_cm = evaluate_model(model, X_test_, y_test_encoded)\n",
    "    test_results[model_name] = {\n",
    "        \"Accuracy\": test_accuracy,\n",
    "        \"Precision\": test_precision,\n",
    "        \"Recall\": test_recall,\n",
    "        \"F1 Score\": test_f1,\n",
    "        \"AUC\": test_auc,\n",
    "        \"Confusion Matrix\": test_cm\n",
    "    }\n",
    "\n",
    "# display the model evaluation results for the validation set\n",
    "train_val_results_df = pd.DataFrame(train_val_results).T\n",
    "print(\"Validation Set Results:\")\n",
    "print(train_val_results_df)\n",
    "\n",
    "# plot confusion matrices for each model on the validation set\n",
    "for model_name, metrics in train_val_results.items():\n",
    "    cm = metrics[\"Confusion Matrix\"]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {model_name} on Validation Set')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "# display the model evaluation results for the test set\n",
    "test_results_df = pd.DataFrame(test_results).T\n",
    "print(\"Test Set Results:\")\n",
    "print(test_results_df)\n",
    "\n",
    "# plot confusion matrices for each model on the test set\n",
    "for model_name, metrics in test_results.items():\n",
    "    cm = metrics[\"Confusion Matrix\"]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {model_name} on Test Set')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "8eIUN-spmnNW"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:33:55.634056Z",
     "start_time": "2024-07-29T17:33:55.622426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('feature_selection/variance_threshold/logistic_regression_near_zero_variance_removed.pkl', 'wb') as file:\n",
    "    pickle.dump(models[\"Logistic Regression\"], file)"
   ],
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
